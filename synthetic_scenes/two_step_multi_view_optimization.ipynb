{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d988f9-c5da-46cc-8fa3-b3ce5b61da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Alen Joy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3194a7-2477-4262-9167-b1d6b4c9072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyredner\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from typing import Union\n",
    "\n",
    "# Use GPU if available\n",
    "pyredner.set_use_gpu(torch.cuda.is_available())\n",
    "pyredner.render_pytorch.print_timing = False\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils.plot_target_image import image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c4c50-dc84-4157-87c9-fc3814da6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_encode(image):\n",
    "    return image ** (1.0/2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285990f-d3d1-46a2-a50b-6f36f8de5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to generate camera poses for synthetic scenes\n",
    "\n",
    "def getPhi(x, y, z):\n",
    "    return math.atan2(math.sqrt(x*x + z * z), y)\n",
    "\n",
    "def getTheta(x, y, z):\n",
    "    return math.atan2(x, -z)\n",
    "\n",
    "\n",
    "def getRadius(x, y, z):\n",
    "    return math.sqrt(x*x + y * y + z * z)\n",
    "\n",
    "def getX(radius, theta, phi):\n",
    "    return radius * math.sin(phi*0.01745) * math.cos(theta*0.01745);\n",
    "\n",
    "\n",
    "def getY(radius, theta, phi):\n",
    "    return radius * math.sin(phi*0.01745) * math.sin(theta*0.01745);\n",
    "\n",
    "\n",
    "def getZ(radius, theta, phi):\n",
    "    return radius * math.cos(phi*0.01745);\n",
    "\n",
    "def generateCameraPoses():\n",
    "    radius = 3\n",
    "    camera_poses = []\n",
    "    for phi in range(20, 121, 30): #controls the different altitude\n",
    "        for theta in range(0, 360, 30): #number of images per orbit\n",
    "            camera_poses.append([getX(radius, theta, phi), getZ(radius, theta, phi), getY(radius, theta, phi)])\n",
    "    return camera_poses            \n",
    "\n",
    "cam_poses = generateCameraPoses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee56d528-a746-485f-bc93-d04d8fb9a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_file = 'data/spot/spot.obj'\n",
    "target_object = pyredner.load_obj(obj_file, return_objects = True)\n",
    "camera = pyredner.automatic_camera_placement(target_object, resolution=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8cf73-3d56-437b-a32b-28d81cc9ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "envmap = pyredner.EnvironmentMap(0.7 * torch.ones(1, 1, 3).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd3be8a-3de4-4d3c-afce-1507399f9887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment below to try with real world outdoor envmap\n",
    "\n",
    "envmap = pyredner.imread('envmap/outdoor.exr')\n",
    "if pyredner.get_use_gpu():\n",
    "    envmap = envmap.cuda(device = pyredner.get_device())\n",
    "envmap = pyredner.EnvironmentMap(envmap, directly_visible= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd127e-3ec9-4846-a68d-0853ac17a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "cams = []\n",
    "for i in range(len(cam_poses)):\n",
    "    cam = pyredner.Camera(position = torch.tensor(cam_poses[i]) ,\n",
    "                         look_at = camera.look_at,\n",
    "                         up = camera.up,\n",
    "                         fov = camera.fov,\n",
    "                         resolution = camera.resolution)\n",
    "    cams.append(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc46a9d-66f7-4599-a95d-7ec7523f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating the target scenes using redner\n",
    "\n",
    "target_scenes = []\n",
    "for j in range(len(cam_poses)):\n",
    "    scene = pyredner.Scene(camera = cams[j], objects = target_object, envmap = envmap)\n",
    "    target_scenes.append(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece837bf-7401-482a-999a-406ac9c87ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rendering and storing all the scene as a batch\n",
    "\n",
    "target_img = []\n",
    "for k in tqdm(range(len(cam_poses))):\n",
    "    target_args = pyredner.RenderFunction.serialize_scene(scene=target_scenes[k],\n",
    "                                                          num_samples = 128,\n",
    "                                                          max_bounces = 2)\n",
    "\n",
    "    render = pyredner.RenderFunction.apply\n",
    "\n",
    "    img = render(0, *target_args)\n",
    "    img = img.clamp(0,1)\n",
    "    target_img.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f6fc51-0858-4edf-9766-670ad073394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(target_img, rows = 6, cols = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a78e2-eb82-4c77-a3cd-3d7f8b2ecb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the geometry to compute the uv_index, vertex and normals\n",
    "material_map, mesh_list, light_map = pyredner.load_obj(obj_file)\n",
    "for _,mesh in mesh_list:\n",
    "    mesh_normals = pyredner.compute_vertex_normal(mesh.vertices, mesh.indices)\n",
    "    computed_uvs = pyredner.compute_uvs(mesh.vertices, mesh.indices)    \n",
    "uv_vertex, uv_index = computed_uvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0655c7-fffa-4521-8fdd-db182d299900",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_resolution = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08557de-88da-4aed-8d01-5955ad320311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing diffuse, specular and roughness, and assigning them as material\n",
    "\n",
    "diffuse_tex = torch.tensor(\\\n",
    "    np.ones((tex_resolution, tex_resolution, 3), dtype=np.float32) * 0.0,\n",
    "    requires_grad = True,\n",
    "    device = pyredner.get_device())\n",
    "\n",
    "\n",
    "specular_tex = torch.tensor(\\\n",
    "        np.ones((tex_resolution,tex_resolution,3),dtype=np.float32)*0.0,\n",
    "        requires_grad = True,\n",
    "        device = pyredner.get_device())\n",
    "\n",
    "\n",
    "roughness_tex = torch.tensor(\\\n",
    "    np.ones((tex_resolution, tex_resolution, 1), dtype=np.float32) * 0.5,\n",
    "    requires_grad = True,\n",
    "    device = pyredner.get_device())\n",
    "\n",
    "mat = pyredner.Material(diffuse_reflectance=pyredner.Texture(diffuse_tex), \n",
    "                       specular_reflectance=pyredner.Texture(specular_tex),\n",
    "                       roughness=pyredner.Texture(roughness_tex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c22f3-d41f-48d2-89f0-51d5b0795098",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = pyredner.Object(vertices = mesh.vertices,\n",
    "                         indices = mesh.indices,\n",
    "                         uvs = uv_vertex,\n",
    "                         uv_indices = uv_index,\n",
    "                         normals = mesh_normals,\n",
    "                         material = mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb873faf-5e48-477b-9a2a-acf13224ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing one sene with initial materials\n",
    "\n",
    "scene = pyredner.Scene(cams[2], objects = [objects], envmap=envmap)\n",
    "img  = pyredner.render_pathtracing(scene=scene, num_samples=128)\n",
    "imshow(gamma_encode(img).detach().cpu());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973bdb9-e917-4961-8257-a8fcded22bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([diffuse_tex], lr = 1e-2 , weight_decay = 1e-4 )\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=65, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394b34d-9c26-463f-a4b5-1322354c9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "num_views_per_iteration = 5 #20\n",
    "losses = []\n",
    "\n",
    "for t in tqdm(range(200)):\n",
    "    print('Iteration: ', t)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    mat.diffuse_reflectance = pyredner.Texture(diffuse_tex)\n",
    "    mat.specular_reflectance = pyredner.Texture(specular_tex)\n",
    "    mat.roughness = pyredner.Texture(roughness_tex)   \n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for j in tqdm(np.random.permutation(len(cams)).tolist()[:num_views_per_iteration]):\n",
    "        \n",
    "        scene = pyredner.Scene(cams[j], objects = [objects], envmap = envmap)\n",
    "        args = pyredner.RenderFunction.serialize_scene(\\\n",
    "                                                  scene = scene,\n",
    "                                                  num_samples = 4, #16,4\n",
    "                                                  max_bounces = 2)\n",
    "        \n",
    "        render = pyredner.RenderFunction.apply\n",
    "\n",
    "        img = render(t+1, *args)\n",
    "        \n",
    "        pyredner.imwrite(img.cpu(),'results/two_step_optimization/iter_{}.png'.format(t))\n",
    "       \n",
    "        loss = torch.pow(img - target_img[j],2).sum()\n",
    "        total_loss += loss \n",
    "   \n",
    "        n+=1\n",
    "        \n",
    "    \n",
    "    total_loss = total_loss / num_views_per_iteration        \n",
    "        \n",
    "    print('Total Loss:', total_loss.item())\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    diffuse_tex.data = diffuse_tex.data.clamp(0, 1)\n",
    "    specular_tex.data = specular_tex.data.clamp(0, 1)\n",
    "    roughness_tex.data = roughness_tex.data.clamp(1e-5, 1)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"({:d}) Loss: {:f}\".format(t, total_loss.item()))\n",
    "    losses.append(total_loss.item())\n",
    "    \n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 6 ,1)\n",
    "    plt.plot(losses)\n",
    "    plt.subplot(1, 6, 2)\n",
    "    imshow(diffuse_tex.detach().cpu())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 6, 3)\n",
    "    imshow(specular_tex.detach().cpu())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 6, 4)\n",
    "    imshow(roughness_tex.detach().cpu())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 6 ,5)\n",
    "    imshow(gamma_encode(img).detach().cpu())\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47035498-3863-4b10-8b4c-8bf573576f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([diffuse_tex,specular_tex, roughness_tex], lr = 0.005 , weight_decay = 1e-4 )\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=120, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5388b-3b05-42f8-b4b6-1c0091dc8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "num_views_per_iteration = 5 #20\n",
    "losses = []\n",
    "\n",
    "for t in tqdm(range(200)):\n",
    "    print('Iteration: ', t)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    mat.diffuse_reflectance = pyredner.Texture(diffuse_tex)\n",
    "    mat.specular_reflectance = pyredner.Texture(specular_tex)\n",
    "    mat.roughness = pyredner.Texture(roughness_tex)   \n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for j in tqdm(np.random.permutation(len(cams)).tolist()[:num_views_per_iteration]):\n",
    "        \n",
    "        scene = pyredner.Scene(cams[j], objects = [objects], envmap = envmap)\n",
    "        args = pyredner.RenderFunction.serialize_scene(\\\n",
    "                                                  scene = scene,\n",
    "                                                  num_samples = 4, #16,4\n",
    "                                                  max_bounces = 2)\n",
    "        \n",
    "        render = pyredner.RenderFunction.apply\n",
    "\n",
    "        img = render(t+1, *args)\n",
    "        \n",
    "        pyredner.imwrite(img.cpu(),'results/two_step_optimization/iter_{}.png'.format(t))\n",
    "       \n",
    "        loss = torch.pow(img - target_img[j],2).sum()\n",
    "        total_loss += loss \n",
    "   \n",
    "        n+=1\n",
    "        \n",
    "    \n",
    "    total_loss = total_loss / num_views_per_iteration        \n",
    "        \n",
    "    print('Total Loss:', total_loss.item())\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    diffuse_tex.data = diffuse_tex.data.clamp(0, 1)\n",
    "    specular_tex.data = specular_tex.data.clamp(0, 1)\n",
    "    roughness_tex.data = roughness_tex.data.clamp(1e-5, 1)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"({:d}) Loss: {:f}\".format(t, total_loss.item()))\n",
    "    losses.append(total_loss.item())\n",
    "    \n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.subplot(1, 6 ,1)\n",
    "    plt.plot(losses)\n",
    "    plt.subplot(1, 6, 2)\n",
    "    imshow(diffuse_tex.detach().cpu())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 6, 3)\n",
    "    imshow(specular_tex.detach().cpu())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 6, 4)\n",
    "    imshow(roughness_tex.detach().cpu())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 6 ,5)\n",
    "    imshow(gamma_encode(img).detach().cpu())\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9ab75-b2b6-4bf3-9505-71a5eeff4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scenes = []\n",
    "for j in range(len(cam_poses)):\n",
    "    scene = pyredner.Scene(camera = cams[j], objects = [objects], envmap = envmap)\n",
    "    final_scenes.append(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e8258-f113-41c2-b55d-12100041e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img = []\n",
    "for k in tqdm(range(len(cam_poses))):\n",
    "    final_args = pyredner.RenderFunction.serialize_scene(scene=final_scenes[k],\n",
    "                                                          num_samples = 128,\n",
    "                                                          max_bounces = 2)\n",
    "\n",
    "    render = pyredner.RenderFunction.apply\n",
    "\n",
    "    img = render(0, *final_args)\n",
    "    img = img.clamp(0,1)\n",
    "#     pyredner.imwrite(img.cpu(), 'results/two_step_optimization/final_{}.png'.format(k))\n",
    "    final_img.append(img.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe5e87-b635-4d6f-8029-8171eef5d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(final_img, rows = 6, cols = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fcb0e4-49f8-4fcb-abfd-074df25a5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from redner, improving the function to save out the obj file and the optimized material maps\n",
    "\n",
    "def save_material(m: pyredner.Material,\n",
    "             filename: str):\n",
    "    if filename[-4:] != '.mtl':\n",
    "        filename = filename + '.mtl'\n",
    "    path = os.path.dirname(filename)\n",
    "\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory != '' and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('newmtl mtl_1\\n')\n",
    "\n",
    "        if m.diffuse_reflectance is not None:\n",
    "            texels = m.diffuse_reflectance.texels\n",
    "            if len(texels.size()) == 1:\n",
    "                f.write('Kd {} {} {}\\n'.format(texels[0], texels[1], texels[2]))\n",
    "            else:\n",
    "                f.write('map_Kd Kd_texels.png\\n')\n",
    "                pyredner.imwrite(texels.data.cpu(), path + '/Kd_texels.png')\n",
    "        \n",
    "        if m.specular_reflectance is not None:\n",
    "            texels = m.specular_reflectance.texels\n",
    "            if len(texels.size()) == 1:\n",
    "                f.write('Ks {} {} {}\\n'.format(texels[0], texels[1], texels[2]))\n",
    "            else:\n",
    "                f.write('map_Ks Ks_texels.png\\n')\n",
    "                pyredner.imwrite(texels.data.cpu(), path + '/Ks_texels.png')\n",
    "                \n",
    "        if m.roughness is not None:\n",
    "            texels = m.roughness.texels\n",
    "            if len(texels.size()) == 1:\n",
    "                f.write('Pr {} {} {}\\n'.format(texels[0], texels[1], texels[2]))\n",
    "            else:\n",
    "                f.write('map_Ns Ns_texels.png\\n')\n",
    "                pyredner.imwrite(texels.data.cpu(), path + '/Ns_texels.png')\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "def save_obj_file(shape: Union[pyredner.Object, pyredner.Shape],\n",
    "             filename: str,\n",
    "             flip_tex_coords = True):\n",
    "\n",
    "\n",
    "    if filename[-4:] != '.obj':\n",
    "        filename = filename + '.obj'\n",
    "    path = os.path.dirname(filename)\n",
    "    name = os.path.basename(filename)[:-4]\n",
    "\n",
    "    save_material(m=shape.material, filename=filename[:-4])\n",
    "\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory != '' and not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('mtllib {}.mtl\\n'.format(name))\n",
    "\n",
    "        vertices = shape.vertices.data.cpu().numpy()\n",
    "        uvs = shape.uvs.cpu().numpy() if shape.uvs is not None else None\n",
    "        normals = shape.normals.data.cpu().numpy() if shape.normals is not None else None\n",
    "        for i in range(vertices.shape[0]):\n",
    "            f.write('v {} {} {}\\n'.format(vertices[i, 0], vertices[i, 1], vertices[i, 2]))\n",
    "        if uvs is not None:\n",
    "            for i in range(uvs.shape[0]):\n",
    "                if flip_tex_coords:\n",
    "                    f.write('vt {} {}\\n'.format(uvs[i, 0], 1 - uvs[i, 1]))\n",
    "                else:\n",
    "                    f.write('vt {} {}\\n'.format(uvs[i, 0], uvs[i, 1]))\n",
    "        if normals is not None:\n",
    "            for i in range(normals.shape[0]):\n",
    "                f.write('vn {} {} {}\\n'.format(normals[i, 0], normals[i, 1], normals[i, 2]))\n",
    "\n",
    "        f.write('usemtl mtl_1\\n')\n",
    "\n",
    "        indices = shape.indices.data.cpu().numpy() + 1\n",
    "        uv_indices = shape.uv_indices.data.cpu().numpy() + 1 if shape.uv_indices is not None else None\n",
    "        normal_indices = shape.normal_indices.data.cpu().numpy() + 1 if shape.normal_indices is not None else None\n",
    "        for i in range(indices.shape[0]):\n",
    "            vi = (indices[i, 0], indices[i, 1], indices[i, 2])\n",
    "            if uv_indices is not None:\n",
    "                uvi = (uv_indices[i, 0], uv_indices[i, 1], uv_indices[i, 2])\n",
    "            else:\n",
    "                if uvs is not None:\n",
    "                    uvi = vi\n",
    "                else:\n",
    "                    uvi = ('', '', '')\n",
    "            if normal_indices is not None:\n",
    "                ni = (normal_indices[i, 0], normal_indices[i, 1], normal_indices[i, 2])\n",
    "            else:\n",
    "                if normals is not None:\n",
    "                    ni = vi\n",
    "                else:\n",
    "                    ni = ('', '', '')\n",
    "            if normals is not None:\n",
    "                f.write('f {}/{}/{} {}/{}/{} {}/{}/{}\\n'.format(\\\n",
    "                    vi[0], uvi[0], ni[0],\n",
    "                    vi[1], uvi[1], ni[1],\n",
    "                    vi[2], uvi[2], ni[2]))\n",
    "            elif uvs is not None:\n",
    "                f.write('f {}/{} {}/{} {}/{}\\n'.format(\\\n",
    "                    vi[0], uvi[0],\n",
    "                    vi[1], uvi[1],\n",
    "                    vi[2], uvi[2]))\n",
    "            else:\n",
    "                f.write('f {} {} {}\\n'.format(\\\n",
    "                    vi[0],\n",
    "                    vi[1],\n",
    "                    vi[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a56245-ff71-4ae1-9bf2-641d44a2aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj_file(objects,'results/two_step_optimization/optimized/spot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
